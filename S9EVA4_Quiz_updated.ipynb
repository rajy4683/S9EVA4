{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S9EVA4_Quiz_updated.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajy4683/S9EVA4/blob/master/S9EVA4_Quiz_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHBAkK9aQmiN",
        "colab_type": "code",
        "outputId": "13950a73-12b6-49f3-da48-80b748b29e05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from datetime import datetime \n",
        "print(\"Current Date/Time: \", datetime.now())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Date/Time:  2020-03-17 16:41:46.573364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkeUIDcSJXUE",
        "colab_type": "code",
        "outputId": "8eb58b48-a5b7-4546-aae6-29b7751e131a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQc6tVsEMKsk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### **[RekogNizer library](https://github.com/rajy4683/RekogNizer.git) contains the following files:**\n",
        "```\n",
        "1. basemodelclass.py:   Contains core model definitions. \n",
        "2. fileutils.py:        Contains utility functions for model_name_generation, plotting functions \n",
        "3. dataloader.py:       Contains dataloaders for both training and test data\n",
        "4. traintest.py:        Contains core training, test and model execution flow routines. \n",
        "5. logger.py:           Contains functions to handle WANDB integration\n",
        "6. hyperparams.py:      Contains values of default hyperparameters alongwith getter and setter functions   \n",
        "7. train_s7_new.py:     Main wrapper script or point of entry. It parses hyperparameters as arguments\n",
        "8. requirements.txt:    Specific libraries that need to be available in the environment\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5sd4efFT2AF",
        "colab_type": "text"
      },
      "source": [
        "#### Downloading and installing dependencies from the GitHub link:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u1pUWK8PGHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/rajy4683/RekogNizer.git /content/drive/My\\ Drive/EVA4/RekogNizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5CIVlNHJeJI",
        "colab_type": "code",
        "outputId": "7e04fe71-3282-433f-89a5-8915e8346185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -r /content/drive/My\\ Drive/EVA4/RekogNizer/requirements.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-ignite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/55/41e8a995876fd2ade29bdba0c3efefa38e7d605cb353c70f3173c04928b5/pytorch_ignite-0.3.0-py2.py3-none-any.whl (103kB)\n",
            "\r\u001b[K     |‚ñà‚ñà‚ñà‚ñè                            | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 112kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 2)) (1.5.1)\n",
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/05/a0bf45b2f4909c3ffb1729deb19355a067a8cf8d56eebd3159d702321b68/wandb-0.8.29-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.4MB 44.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 5)) (1.18.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 7)) (0.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 8)) (3.2.0)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 9)) (0.1.12)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 3)) (7.1.1)\n",
            "Collecting gql==0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/6f/cf9a3056045518f06184e804bae89390eb706168349daa9dff8ac609962a/gql-0.2.0.tar.gz\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/2f/6a366d56c9b1355b0880be9ea66b166cb3536392638d8d91413ec66305ad/GitPython-3.1.0-py3-none-any.whl (450kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 460kB 51.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 3)) (7.352.0)\n",
            "Collecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/c3/ed6d992006837e011baca89476a4bbffb0a91602432f73bd4473816c76e2/watchdog-0.10.2.tar.gz (95kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102kB 13.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 3)) (2.21.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 3)) (3.13)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102kB 12.5MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/2a/95ed0501cf5d8709490b1d3a3f9b5cf340da6c433f896bbe9ce08dbe6785/configparser-4.0.2-py2.py3-none-any.whl\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/e6/058c2dc4723b3647a8cf61385c61f284bfbd0d0657bc5623c22e9ef45a3c/sentry_sdk-0.14.2-py2.py3-none-any.whl (96kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102kB 11.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 3)) (1.12.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 3)) (5.4.8)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 7)) (7.0.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 8)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 8)) (2.4.6)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 634kB 38.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from albumentations->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 9)) (4.1.2.30)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 9)) (1.4.1)\n",
            "Collecting graphql-core<2,>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/89/00ad5e07524d8c523b14d70c685e0299a8b0de6d0727e368c41b89b7ed0b/graphql-core-1.1.tar.gz (70kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71kB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 3)) (2.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/f5/8f84b3bf9d94bdf2454a302f2fa375832b53660ea532586b8a55ff16ae9a/gitdb-4.0.2-py3-none-any.whl (63kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71kB 11.0MB/s \n",
            "\u001b[?25hCollecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 3)) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 3)) (2019.11.28)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 8)) (45.2.0)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 9)) (0.16.2)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/35/d2/27777ab463cd44842c78305fa8097dfba0d94768abbb7e1c4d88f1fa1a0b/smmap-3.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 9)) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 9)) (2.4)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 9)) (2.4.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->-r /content/drive/My Drive/EVA4/RekogNizer/requirements.txt (line 9)) (4.4.2)\n",
            "Building wheels for collected packages: gql, watchdog, subprocess32, imgaug, graphql-core, pathtools\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.2.0-cp36-none-any.whl size=7630 sha256=98f1c5bba4e7e64e8156c8101411dfd5e5ac7de6107ce3a592922bf024ee7afe\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/0e/7b/58a8a5268655b3ad74feef5aa97946f0addafb3cbb6bd2da23\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.2-cp36-none-any.whl size=73605 sha256=f1b941e6eae4dfd3dc845e07af84d7a6f1bf41ed3eb106f08dea5fce08161564\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/ed/6c/028dea90d31b359cd2a7c8b0da4db80e41d24a59614154072e\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=21abc9b6075b3fb21ad18df058ec23aa50783671a891a037db2bd18c041e9ccb\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=6877066c48223e7f5b4816d7f906379f784b6e105b836c40b6c3cfc4d68e5b24\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphql-core: filename=graphql_core-1.1-cp36-none-any.whl size=104650 sha256=45297bed062cc1da834122141e6b142c5fdd0a6876a35e57c6da47c1f90a4b29\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/99/d7/c424029bb0fe910c63b68dbf2aa20d3283d023042521bcd7d5\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8784 sha256=bd25ee876b9218effd9d44cbfc76e4db49d6d7c35315e6c517d5c2b2d28dcd4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built gql watchdog subprocess32 imgaug graphql-core pathtools\n",
            "Installing collected packages: pytorch-ignite, graphql-core, gql, smmap, gitdb, GitPython, pathtools, watchdog, subprocess32, configparser, sentry-sdk, shortuuid, docker-pycreds, wandb, imgaug\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "Successfully installed GitPython-3.1.0 configparser-4.0.2 docker-pycreds-0.4.0 gitdb-4.0.2 gql-0.2.0 graphql-core-1.1 imgaug-0.2.6 pathtools-0.1.2 pytorch-ignite-0.3.0 sentry-sdk-0.14.2 shortuuid-1.0.1 smmap-3.0.1 subprocess32-3.5.4 wandb-0.8.29 watchdog-0.10.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfblgxgzgYN4",
        "colab_type": "code",
        "outputId": "31bdfe55-ba35-4fcc-cfba-909f59d66654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "!pip install -U git+https://github.com/albu/albumentations"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/albu/albumentations\n",
            "  Cloning https://github.com/albu/albumentations to /tmp/pip-req-build-big4ppfp\n",
            "  Running command git clone -q https://github.com/albu/albumentations /tmp/pip-req-build-big4ppfp\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (1.18.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: imgaug<0.2.7,>=0.2.5 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (0.2.6)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (3.2.0)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4.6)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (45.2.0)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.5-cp36-none-any.whl size=64514 sha256=1dc9575158bc03589cf19500ed73c773e02d77f6cd3ec6e7ad079eef9673791f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ittnbiu7/wheels/45/8b/e4/2837bbcf517d00732b8e394f8646f22b8723ac00993230188b\n",
            "Successfully built albumentations\n",
            "Installing collected packages: albumentations\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7HkockSqqMe",
        "colab_type": "code",
        "outputId": "17c000ad-745d-44e3-c08f-63ee80ce95bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "!pip install --upgrade pyforest"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyforest\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/c3/ae8976c2c281c69aef2a615e8e3e6ce8c0b401c55dd68c50911d0d532b3b/pyforest-1.0.2.tar.gz\n",
            "Building wheels for collected packages: pyforest\n",
            "  Building wheel for pyforest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyforest: filename=pyforest-1.0.2-py2.py3-none-any.whl size=13556 sha256=f7f31b7e07e16248d312f2d0276f7eed0bc9656465c4b0fa9e93d25833b8d141\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/1b/b1/f7ff0a6aee79ec158aea4a339d7bd722deb261f65d8c9968c2\n",
            "Successfully built pyforest\n",
            "Installing collected packages: pyforest\n",
            "Successfully installed pyforest-1.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xUymEZyqufL",
        "colab_type": "code",
        "outputId": "b848458c-ecea-44c7-a4ea-423fcfd9319e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "!python -m pyforest install_extensions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting to install pyforest extensions for Jupyter Notebook and Jupyter Lab\n",
            "\n",
            "Trying to install pyforest nbextension...\n",
            "\n",
            "Finished installing the pyforest Jupyter Notebook nbextension\n",
            "Please reload your Jupyter notebook browser window\n",
            "\n",
            "Trying to install pyforest labextension...\n",
            "Could not install pyforest Jupyter Lab extension because Jupyter Lab is not available\n",
            "\n",
            "Finished installing the pyforest Jupyter extensions\n",
            "Please reload your Jupyter notebook and/or Jupyter lab browser windows\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meia7p02UJE8",
        "colab_type": "text"
      },
      "source": [
        "#### WANDB client login"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi9SBc2TKUF3",
        "colab_type": "code",
        "outputId": "98a46cc6-de83-4c72-cbbb-f83839404a4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!wandb login a6f947d2d2f69e7a8c8ca0f69811fd554f27d204"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFb9EtN4KdDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sys.path.append('/content/drive/My Drive/EVA4/')\n",
        "sys.path.append('/content/drive/My Drive/EVA4/RekogNizer')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OfqGcVevk70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!cp /content/drive/My\\ Drive/EVA4/RekogNizer/train_s8_new.py /content/drive/My\\ Drive/EVA4/RekogNizer/train_s9_new.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaRJ9X1FVHxH",
        "colab_type": "text"
      },
      "source": [
        "train_s8_new.py currently can take JSON formatted string as input. Following parameters are configurable and are used in the model training and execution.\n",
        "```\n",
        "{\"project\": \"news5\", \n",
        " \"sched_lr_gamma\": 0.5, \n",
        " \"no_cuda\": false, \n",
        " \"dropout\": 0.1, \n",
        " \"test_batch_size\": 128, \n",
        " \"batch_size\": 128, \n",
        " \"epochs\": 45, \n",
        " \"bias\": false, \n",
        " \"lr\": 0.001, \n",
        " \"start_lr\": 0, \n",
        " \"sched_lr_step\": 1, \n",
        " \"weight_decay\": 0.0, \n",
        " \"seed\": 1, \n",
        " \"momentum\": 0.9}\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6cgY-URcar_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sys.path.append('/content/drive/My Drive/EVA4/')\n",
        "sys.path.append('/content/drive/My Drive/EVA4/RekogNizer')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6Mbw0QScb1L",
        "colab_type": "code",
        "outputId": "4dab18fa-7e9a-4e19-9e51-8f71d4db40cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!wandb login a6f947d2d2f69e7a8c8ca0f69811fd554f27d204"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYI_ilefb7MT",
        "colab_type": "code",
        "outputId": "8136c546-82d8-4375-9374-8464db4559bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from RekogNizer import hyperparams\n",
        "from RekogNizer import basemodelclass\n",
        "from RekogNizer import fileutils\n",
        "from RekogNizer import dataloader\n",
        "from RekogNizer import traintest\n",
        "from RekogNizer import logger\n",
        "from RekogNizer import QuizDNN\n",
        "from torchsummary import summary\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import argparse\n",
        "import json\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from albumentations import (\n",
        "    HorizontalFlip, Compose, RandomCrop, Cutout,Normalize, HorizontalFlip, \n",
        "    Resize,RandomSizedCrop, MotionBlur\n",
        ")\n",
        "from albumentations.pytorch import ToTensor\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFBEQd8bfe5F",
        "colab_type": "code",
        "outputId": "03d21461-23ea-4ba5-b1d6-837714d15e72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "from torchsummary import summary\n",
        "my_model = QuizDNN.S9QuizDNN(dropout=0.1)\n",
        "summary(my_model.to(torch.device(\"cuda\")),input_size=(3, 32, 32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]             192\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8           [-1, 64, 16, 16]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
            "           Conv2d-10           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 16, 16]             128\n",
            "           Conv2d-12           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 16, 16]             128\n",
            "        MaxPool2d-14             [-1, 64, 8, 8]               0\n",
            "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
            "           Conv2d-17             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
            "           Conv2d-19             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-20             [-1, 64, 8, 8]             128\n",
            "AdaptiveAvgPool2d-21             [-1, 64, 1, 1]               0\n",
            "           Conv2d-22             [-1, 10, 1, 1]             640\n",
            "================================================================\n",
            "Total params: 261,760\n",
            "Trainable params: 261,760\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 4.09\n",
            "Params size (MB): 1.00\n",
            "Estimated Total Size (MB): 5.10\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrAGwYjCkeor",
        "colab_type": "code",
        "outputId": "a2ac7c69-552d-42db-a821-3d05703f6488",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/drive/My\\ Drive/EVA4/RekogNizer/train_s9_new.py -p '{\"lr\":0.5,\"dropout\":0.1, \"momentum\":0.9, \"epochs\":40, \"weight_decay\":0.00015753761358641488}'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting  lr  =  0.5\n",
            "Setting  dropout  =  0.1\n",
            "Setting  momentum  =  0.9\n",
            "Setting  epochs  =  40\n",
            "Setting  weight_decay  =  0.00015753761358641488\n",
            "Final Hyperparameters\n",
            "             dropout : 0.1 \n",
            "          batch_size : 128 \n",
            "     test_batch_size : 128 \n",
            "                  lr : 0.5 \n",
            "            momentum : 0.9 \n",
            "             no_cuda : False \n",
            "                seed : 1 \n",
            "              epochs : 40 \n",
            "                bias : False \n",
            "      sched_lr_gamma : 0.5 \n",
            "       sched_lr_step : 1 \n",
            "            start_lr : 0 \n",
            "        weight_decay : 0.00015753761358641488 \n",
            "             project : news5 \n",
            "Initializing datasets and dataloaders\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.8.29\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200317_183204-13lzotk4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msweet-breeze-872\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/rajy4683/news5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/rajy4683/news5/runs/13lzotk4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "Model saved to:  /content/drive/My Drive/EVA4/model_saves/model-5e85033075.h5\n",
            "Hyper Params:\n",
            "wandb_version: 1\n",
            "\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.29\n",
            "    code_path: code/drive/My Drive/EVA4/RekogNizer/train_s9_new.py\n",
            "    framework: torch\n",
            "    is_jupyter_run: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 128\n",
            "bias:\n",
            "  desc: null\n",
            "  value: false\n",
            "dropout:\n",
            "  desc: null\n",
            "  value: 0.1\n",
            "epochs:\n",
            "  desc: null\n",
            "  value: 40\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.5\n",
            "momentum:\n",
            "  desc: null\n",
            "  value: 0.9\n",
            "no_cuda:\n",
            "  desc: null\n",
            "  value: false\n",
            "project:\n",
            "  desc: null\n",
            "  value: news5\n",
            "run_name:\n",
            "  desc: null\n",
            "  value: 5e85033075\n",
            "sched_lr_gamma:\n",
            "  desc: null\n",
            "  value: 0.5\n",
            "sched_lr_step:\n",
            "  desc: null\n",
            "  value: 1\n",
            "seed:\n",
            "  desc: null\n",
            "  value: 1\n",
            "start_lr:\n",
            "  desc: null\n",
            "  value: 0\n",
            "test_batch_size:\n",
            "  desc: null\n",
            "  value: 128\n",
            "weight_decay:\n",
            "  desc: null\n",
            "  value: 0.00015753761358641488\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]             192\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8           [-1, 64, 16, 16]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
            "           Conv2d-10           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 16, 16]             128\n",
            "           Conv2d-12           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 16, 16]             128\n",
            "        MaxPool2d-14             [-1, 64, 8, 8]               0\n",
            "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
            "           Conv2d-17             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
            "           Conv2d-19             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-20             [-1, 64, 8, 8]             128\n",
            "AdaptiveAvgPool2d-21             [-1, 64, 1, 1]               0\n",
            "           Conv2d-22             [-1, 10, 1, 1]             640\n",
            "================================================================\n",
            "Total params: 261,760\n",
            "Trainable params: 261,760\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 4.09\n",
            "Params size (MB): 1.00\n",
            "Estimated Total Size (MB): 5.10\n",
            "----------------------------------------------------------------\n",
            "loss=0.9149417877197266 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 37.11it/s]\n",
            "\n",
            "Epoch: 1 Train set: Average loss: 0.0111, Accuracy: 47.942%\n",
            "Epoch: 1 Test set: Average loss: 1.7598, Accuracy: 46.600%\n",
            "Model saved as Test Accuracy increased from  0.0  to  46.6\n",
            "loss=0.7805065512657166 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 37.41it/s]\n",
            "\n",
            "Epoch: 2 Train set: Average loss: 0.0074, Accuracy: 65.986%\n",
            "Epoch: 2 Test set: Average loss: 1.6552, Accuracy: 46.500%\n",
            "loss=0.6464975476264954 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 40.34it/s]\n",
            "\n",
            "Epoch: 3 Train set: Average loss: 0.0059, Accuracy: 73.602%\n",
            "Epoch: 3 Test set: Average loss: 1.5285, Accuracy: 52.990%\n",
            "Model saved as Test Accuracy increased from  46.6  to  52.99\n",
            "loss=0.7704671621322632 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 36.99it/s]\n",
            "\n",
            "Epoch: 4 Train set: Average loss: 0.0050, Accuracy: 77.588%\n",
            "Epoch: 4 Test set: Average loss: 0.9854, Accuracy: 65.820%\n",
            "Model saved as Test Accuracy increased from  52.99  to  65.82\n",
            "loss=0.6582034826278687 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 37.10it/s]\n",
            "\n",
            "Epoch: 5 Train set: Average loss: 0.0045, Accuracy: 80.032%\n",
            "Epoch: 5 Test set: Average loss: 1.1471, Accuracy: 60.660%\n",
            "loss=0.4709346294403076 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 37.10it/s]\n",
            "\n",
            "Epoch: 6 Train set: Average loss: 0.0040, Accuracy: 82.192%\n",
            "Epoch: 6 Test set: Average loss: 1.7485, Accuracy: 51.910%\n",
            "loss=0.6776091456413269 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 37.24it/s]\n",
            "\n",
            "Epoch: 7 Train set: Average loss: 0.0035, Accuracy: 84.548%\n",
            "Epoch: 7 Test set: Average loss: 1.4728, Accuracy: 55.880%\n",
            "loss=0.3379673957824707 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 37.05it/s]\n",
            "\n",
            "Epoch: 8 Train set: Average loss: 0.0030, Accuracy: 86.690%\n",
            "Epoch: 8 Test set: Average loss: 1.6360, Accuracy: 55.850%\n",
            "loss=0.223348468542099 batch_id=390: 100%|‚ñà‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 37.47it/s]\n",
            "\n",
            "Epoch: 9 Train set: Average loss: 0.0025, Accuracy: 89.212%\n",
            "Epoch: 9 Test set: Average loss: 0.9669, Accuracy: 68.740%\n",
            "Model saved as Test Accuracy increased from  65.82  to  68.74\n",
            "loss=0.20005115866661072 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 37.05it/s]\n",
            "\n",
            "Epoch: 10 Train set: Average loss: 0.0017, Accuracy: 92.706%\n",
            "Epoch: 10 Test set: Average loss: 1.1393, Accuracy: 68.220%\n",
            "loss=0.08682005852460861 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 37.23it/s]\n",
            "\n",
            "Epoch: 11 Train set: Average loss: 0.0011, Accuracy: 95.714%\n",
            "Epoch: 11 Test set: Average loss: 1.3391, Accuracy: 63.790%\n",
            "loss=0.3865329325199127 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 37.21it/s]\n",
            "\n",
            "Epoch: 12 Train set: Average loss: 0.0019, Accuracy: 91.250%\n",
            "Epoch: 12 Test set: Average loss: 1.5204, Accuracy: 56.740%\n",
            "loss=0.4666077494621277 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 39.35it/s]\n",
            "\n",
            "Epoch: 13 Train set: Average loss: 0.0026, Accuracy: 88.446%\n",
            "Epoch: 13 Test set: Average loss: 1.8764, Accuracy: 53.260%\n",
            "loss=0.5867513418197632 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 36.95it/s]\n",
            "\n",
            "Epoch: 14 Train set: Average loss: 0.0029, Accuracy: 87.166%\n",
            "Epoch: 14 Test set: Average loss: 0.7441, Accuracy: 74.780%\n",
            "Model saved as Test Accuracy increased from  68.74  to  74.78\n",
            "loss=0.6547752618789673 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 37.03it/s]\n",
            "\n",
            "Epoch: 15 Train set: Average loss: 0.0029, Accuracy: 87.182%\n",
            "Epoch: 15 Test set: Average loss: 1.9795, Accuracy: 49.380%\n",
            "loss=0.3008486330509186 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 37.16it/s]\n",
            "\n",
            "Epoch: 16 Train set: Average loss: 0.0029, Accuracy: 87.182%\n",
            "Epoch: 16 Test set: Average loss: 1.2185, Accuracy: 63.480%\n",
            "loss=0.4659547209739685 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 37.20it/s]\n",
            "\n",
            "Epoch: 17 Train set: Average loss: 0.0026, Accuracy: 88.748%\n",
            "Epoch: 17 Test set: Average loss: 0.7780, Accuracy: 73.440%\n",
            "loss=0.17437003552913666 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 37.06it/s]\n",
            "\n",
            "Epoch: 18 Train set: Average loss: 0.0022, Accuracy: 90.584%\n",
            "Epoch: 18 Test set: Average loss: 1.1699, Accuracy: 66.700%\n",
            "loss=0.22732725739479065 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 36.97it/s]\n",
            "\n",
            "Epoch: 19 Train set: Average loss: 0.0017, Accuracy: 92.458%\n",
            "Epoch: 19 Test set: Average loss: 1.1782, Accuracy: 68.300%\n",
            "loss=0.08968521654605865 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 37.12it/s]\n",
            "\n",
            "Epoch: 20 Train set: Average loss: 0.0010, Accuracy: 95.892%\n",
            "Epoch: 20 Test set: Average loss: 0.8349, Accuracy: 75.050%\n",
            "Model saved as Test Accuracy increased from  74.78  to  75.05\n",
            "loss=0.037854235619306564 batch_id=390: 100%|‚ñà| 391/391 [00:10<00:00, 37.09it/s]\n",
            "\n",
            "Epoch: 21 Train set: Average loss: 0.0004, Accuracy: 98.698%\n",
            "Epoch: 21 Test set: Average loss: 0.9562, Accuracy: 71.770%\n",
            "loss=0.31140390038490295 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 37.31it/s]\n",
            "\n",
            "Epoch: 22 Train set: Average loss: 0.0008, Accuracy: 96.808%\n",
            "Epoch: 22 Test set: Average loss: 1.8396, Accuracy: 60.140%\n",
            "loss=0.3487779200077057 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 37.05it/s]\n",
            "\n",
            "Epoch: 23 Train set: Average loss: 0.0019, Accuracy: 91.572%\n",
            "Epoch: 23 Test set: Average loss: 1.0598, Accuracy: 66.750%\n",
            "loss=0.2753564119338989 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 36.91it/s]\n",
            "\n",
            "Epoch: 24 Train set: Average loss: 0.0023, Accuracy: 89.688%\n",
            "Epoch: 24 Test set: Average loss: 1.0723, Accuracy: 66.380%\n",
            "loss=0.4400825500488281 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 36.81it/s]\n",
            "\n",
            "Epoch: 25 Train set: Average loss: 0.0025, Accuracy: 88.638%\n",
            "Epoch: 25 Test set: Average loss: 1.5737, Accuracy: 59.720%\n",
            "loss=0.23003587126731873 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 39.07it/s]\n",
            "\n",
            "Epoch: 26 Train set: Average loss: 0.0026, Accuracy: 88.376%\n",
            "Epoch: 26 Test set: Average loss: 1.3206, Accuracy: 59.700%\n",
            "loss=0.3787837624549866 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 36.97it/s]\n",
            "\n",
            "Epoch: 27 Train set: Average loss: 0.0023, Accuracy: 89.812%\n",
            "Epoch: 27 Test set: Average loss: 1.1675, Accuracy: 65.310%\n",
            "loss=0.2854112982749939 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 37.10it/s]\n",
            "\n",
            "Epoch: 28 Train set: Average loss: 0.0020, Accuracy: 91.136%\n",
            "Epoch: 28 Test set: Average loss: 0.8774, Accuracy: 73.790%\n",
            "loss=0.19807498157024384 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 37.03it/s]\n",
            "\n",
            "Epoch: 29 Train set: Average loss: 0.0015, Accuracy: 93.392%\n",
            "Epoch: 29 Test set: Average loss: 0.7499, Accuracy: 75.650%\n",
            "Model saved as Test Accuracy increased from  75.05  to  75.65\n",
            "loss=0.06354305893182755 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 36.86it/s]\n",
            "\n",
            "Epoch: 30 Train set: Average loss: 0.0008, Accuracy: 96.556%\n",
            "Epoch: 30 Test set: Average loss: 0.7580, Accuracy: 75.300%\n",
            "loss=0.08331570029258728 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 37.38it/s]\n",
            "\n",
            "Epoch: 31 Train set: Average loss: 0.0003, Accuracy: 99.128%\n",
            "Epoch: 31 Test set: Average loss: 0.8093, Accuracy: 75.650%\n",
            "loss=0.12626180052757263 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 36.81it/s]\n",
            "\n",
            "Epoch: 32 Train set: Average loss: 0.0003, Accuracy: 98.870%\n",
            "Epoch: 32 Test set: Average loss: 0.7652, Accuracy: 76.090%\n",
            "Model saved as Test Accuracy increased from  75.65  to  76.09\n",
            "loss=0.25524646043777466 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 37.02it/s]\n",
            "\n",
            "Epoch: 33 Train set: Average loss: 0.0015, Accuracy: 93.208%\n",
            "Epoch: 33 Test set: Average loss: 1.0371, Accuracy: 66.540%\n",
            "loss=0.26654383540153503 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 37.33it/s]\n",
            "\n",
            "Epoch: 34 Train set: Average loss: 0.0021, Accuracy: 90.746%\n",
            "Epoch: 34 Test set: Average loss: 0.8990, Accuracy: 70.900%\n",
            "loss=0.36068326234817505 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 39.81it/s]\n",
            "\n",
            "Epoch: 35 Train set: Average loss: 0.0023, Accuracy: 89.814%\n",
            "Epoch: 35 Test set: Average loss: 2.5755, Accuracy: 43.600%\n",
            "loss=0.4852820932865143 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:10<00:00, 38.65it/s]\n",
            "\n",
            "Epoch: 36 Train set: Average loss: 0.0024, Accuracy: 89.236%\n",
            "Epoch: 36 Test set: Average loss: 1.7766, Accuracy: 52.570%\n",
            "loss=0.13746318221092224 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 37.08it/s]\n",
            "\n",
            "Epoch: 37 Train set: Average loss: 0.0022, Accuracy: 90.148%\n",
            "Epoch: 37 Test set: Average loss: 1.1697, Accuracy: 64.650%\n",
            "loss=0.19038645923137665 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 36.94it/s]\n",
            "\n",
            "Epoch: 38 Train set: Average loss: 0.0019, Accuracy: 91.778%\n",
            "Epoch: 38 Test set: Average loss: 1.0737, Accuracy: 66.430%\n",
            "loss=0.17231519520282745 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 37.18it/s]\n",
            "\n",
            "Epoch: 39 Train set: Average loss: 0.0015, Accuracy: 93.330%\n",
            "Epoch: 39 Test set: Average loss: 0.8156, Accuracy: 75.040%\n",
            "loss=0.09257079660892487 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:10<00:00, 39.16it/s]\n",
            "\n",
            "Epoch: 40 Train set: Average loss: 0.0009, Accuracy: 96.364%\n",
            "Epoch: 40 Test set: Average loss: 0.7824, Accuracy: 74.900%\n",
            "Final model save path: /content/drive/My Drive/EVA4/model_saves/model-5e85033075.h5  best Accuracy: 76.09\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 5056\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   Train Accuracy 96.364\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            _step 39\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       Train Loss 0.0008669189498573542\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        Test Loss 0.7823628992080689\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    Learning Rate 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                         _runtime 485.34819531440735\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    Test Accuracy 74.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       _timestamp 1584470407.2027717\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing files in wandb/run-20200317_183204-13lzotk4:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   code/drive/My Drive/EVA4/RekogNizer/train_s9_new.py\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: plus 7 W&B file(s) and 1 media file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced sweet-breeze-872: https://app.wandb.ai/rajy4683/news5/runs/13lzotk4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeULShEmgAxr",
        "colab_type": "code",
        "outputId": "bdf7204f-6bfa-4bf0-af38-1fe2fb921231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/drive/My\\ Drive/EVA4/RekogNizer/train_s9_new.py -p '{\"lr\":0.5,\"dropout\":0.1, \"momentum\":0.9, \"epochs\":100, \"weight_decay\":0.00015753761358641488}'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting  lr  =  0.5\n",
            "Setting  dropout  =  0.1\n",
            "Setting  momentum  =  0.9\n",
            "Setting  epochs  =  100\n",
            "Setting  weight_decay  =  0.00015753761358641488\n",
            "Final Hyperparameters\n",
            "             dropout : 0.1 \n",
            "          batch_size : 128 \n",
            "     test_batch_size : 128 \n",
            "                  lr : 0.5 \n",
            "            momentum : 0.9 \n",
            "             no_cuda : False \n",
            "                seed : 1 \n",
            "              epochs : 100 \n",
            "                bias : False \n",
            "      sched_lr_gamma : 0.5 \n",
            "       sched_lr_step : 1 \n",
            "            start_lr : 0 \n",
            "        weight_decay : 0.00015753761358641488 \n",
            "             project : news5 \n",
            "Initializing datasets and dataloaders\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.8.29\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200317_183134-fphnu6h1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpolished-shadow-870\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/rajy4683/news5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/rajy4683/news5/runs/fphnu6h1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "Model saved to:  /content/drive/My Drive/EVA4/model_saves/model-19de5c66a3.h5\n",
            "Hyper Params:\n",
            "wandb_version: 1\n",
            "\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.29\n",
            "    code_path: code/drive/My Drive/EVA4/RekogNizer/train_s9_new.py\n",
            "    framework: torch\n",
            "    is_jupyter_run: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 128\n",
            "bias:\n",
            "  desc: null\n",
            "  value: false\n",
            "dropout:\n",
            "  desc: null\n",
            "  value: 0.1\n",
            "epochs:\n",
            "  desc: null\n",
            "  value: 100\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.5\n",
            "momentum:\n",
            "  desc: null\n",
            "  value: 0.9\n",
            "no_cuda:\n",
            "  desc: null\n",
            "  value: false\n",
            "project:\n",
            "  desc: null\n",
            "  value: news5\n",
            "run_name:\n",
            "  desc: null\n",
            "  value: 19de5c66a3\n",
            "sched_lr_gamma:\n",
            "  desc: null\n",
            "  value: 0.5\n",
            "sched_lr_step:\n",
            "  desc: null\n",
            "  value: 1\n",
            "seed:\n",
            "  desc: null\n",
            "  value: 1\n",
            "start_lr:\n",
            "  desc: null\n",
            "  value: 0\n",
            "test_batch_size:\n",
            "  desc: null\n",
            "  value: 128\n",
            "weight_decay:\n",
            "  desc: null\n",
            "  value: 0.00015753761358641488\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]             192\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8           [-1, 64, 16, 16]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
            "           Conv2d-10           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 16, 16]             128\n",
            "           Conv2d-12           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 16, 16]             128\n",
            "        MaxPool2d-14             [-1, 64, 8, 8]               0\n",
            "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
            "           Conv2d-17             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
            "           Conv2d-19             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-20             [-1, 64, 8, 8]             128\n",
            "AdaptiveAvgPool2d-21             [-1, 64, 1, 1]               0\n",
            "           Conv2d-22             [-1, 10, 1, 1]             640\n",
            "================================================================\n",
            "Total params: 261,760\n",
            "Trainable params: 261,760\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 4.09\n",
            "Params size (MB): 1.00\n",
            "Estimated Total Size (MB): 5.10\n",
            "----------------------------------------------------------------\n",
            "loss=0.8416963815689087 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.27it/s]\n",
            "\n",
            "Epoch: 1 Train set: Average loss: 0.0110, Accuracy: 48.252%\n",
            "Epoch: 1 Test set: Average loss: 2.4034, Accuracy: 36.990%\n",
            "Model saved as Test Accuracy increased from  0.0  to  36.99\n",
            "loss=0.7348772883415222 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.44it/s]\n",
            "\n",
            "Epoch: 2 Train set: Average loss: 0.0073, Accuracy: 66.726%\n",
            "Epoch: 2 Test set: Average loss: 2.1597, Accuracy: 41.830%\n",
            "Model saved as Test Accuracy increased from  36.99  to  41.83\n",
            "loss=0.6228448152542114 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.43it/s]\n",
            "\n",
            "Epoch: 3 Train set: Average loss: 0.0058, Accuracy: 73.836%\n",
            "Epoch: 3 Test set: Average loss: 1.1823, Accuracy: 61.330%\n",
            "Model saved as Test Accuracy increased from  41.83  to  61.33\n",
            "loss=0.7535073161125183 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.27it/s]\n",
            "\n",
            "Epoch: 4 Train set: Average loss: 0.0050, Accuracy: 77.822%\n",
            "Epoch: 4 Test set: Average loss: 1.2890, Accuracy: 56.760%\n",
            "loss=0.684924304485321 batch_id=390: 100%|‚ñà‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.39it/s]\n",
            "\n",
            "Epoch: 5 Train set: Average loss: 0.0045, Accuracy: 80.088%\n",
            "Epoch: 5 Test set: Average loss: 1.3056, Accuracy: 59.700%\n",
            "loss=0.5487304925918579 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.42it/s]\n",
            "\n",
            "Epoch: 6 Train set: Average loss: 0.0040, Accuracy: 82.230%\n",
            "Epoch: 6 Test set: Average loss: 1.2136, Accuracy: 62.650%\n",
            "Model saved as Test Accuracy increased from  61.33  to  62.65\n",
            "loss=0.6357468962669373 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.40it/s]\n",
            "\n",
            "Epoch: 7 Train set: Average loss: 0.0035, Accuracy: 84.408%\n",
            "Epoch: 7 Test set: Average loss: 1.3044, Accuracy: 58.860%\n",
            "loss=0.3057400584220886 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.51it/s]\n",
            "\n",
            "Epoch: 8 Train set: Average loss: 0.0030, Accuracy: 86.596%\n",
            "Epoch: 8 Test set: Average loss: 1.2285, Accuracy: 62.570%\n",
            "loss=0.21555574238300323 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:33<00:00, 12.37it/s]\n",
            "\n",
            "Epoch: 9 Train set: Average loss: 0.0025, Accuracy: 89.058%\n",
            "Epoch: 9 Test set: Average loss: 1.1112, Accuracy: 66.180%\n",
            "Model saved as Test Accuracy increased from  62.65  to  66.18\n",
            "loss=0.1556723415851593 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.48it/s]\n",
            "\n",
            "Epoch: 10 Train set: Average loss: 0.0017, Accuracy: 92.880%\n",
            "Epoch: 10 Test set: Average loss: 1.0487, Accuracy: 69.250%\n",
            "Model saved as Test Accuracy increased from  66.18  to  69.25\n",
            "loss=0.19999083876609802 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:33<00:00, 12.16it/s]\n",
            "\n",
            "Epoch: 11 Train set: Average loss: 0.0010, Accuracy: 95.798%\n",
            "Epoch: 11 Test set: Average loss: 1.3594, Accuracy: 64.760%\n",
            "loss=0.3883483409881592 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.35it/s]\n",
            "\n",
            "Epoch: 12 Train set: Average loss: 0.0019, Accuracy: 91.302%\n",
            "Epoch: 12 Test set: Average loss: 0.9531, Accuracy: 70.030%\n",
            "Model saved as Test Accuracy increased from  69.25  to  70.03\n",
            "loss=0.45334750413894653 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:33<00:00, 11.72it/s]\n",
            "\n",
            "Epoch: 13 Train set: Average loss: 0.0026, Accuracy: 88.442%\n",
            "Epoch: 13 Test set: Average loss: 3.4578, Accuracy: 39.970%\n",
            "loss=0.4799356460571289 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.37it/s]\n",
            "\n",
            "Epoch: 14 Train set: Average loss: 0.0029, Accuracy: 87.102%\n",
            "Epoch: 14 Test set: Average loss: 1.2223, Accuracy: 60.190%\n",
            "loss=0.5767033696174622 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.44it/s]\n",
            "\n",
            "Epoch: 15 Train set: Average loss: 0.0029, Accuracy: 87.116%\n",
            "Epoch: 15 Test set: Average loss: 1.4474, Accuracy: 61.680%\n",
            "loss=0.30302315950393677 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:33<00:00, 12.45it/s]\n",
            "\n",
            "Epoch: 16 Train set: Average loss: 0.0028, Accuracy: 87.434%\n",
            "Epoch: 16 Test set: Average loss: 1.4383, Accuracy: 63.990%\n",
            "loss=0.385315477848053 batch_id=390: 100%|‚ñà‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.41it/s]\n",
            "\n",
            "Epoch: 17 Train set: Average loss: 0.0025, Accuracy: 88.684%\n",
            "Epoch: 17 Test set: Average loss: 0.8879, Accuracy: 72.790%\n",
            "Model saved as Test Accuracy increased from  70.03  to  72.79\n",
            "loss=0.2304716557264328 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.37it/s]\n",
            "\n",
            "Epoch: 18 Train set: Average loss: 0.0021, Accuracy: 90.560%\n",
            "Epoch: 18 Test set: Average loss: 1.0230, Accuracy: 68.200%\n",
            "loss=0.15092569589614868 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:33<00:00, 12.47it/s]\n",
            "\n",
            "Epoch: 19 Train set: Average loss: 0.0017, Accuracy: 92.556%\n",
            "Epoch: 19 Test set: Average loss: 1.2867, Accuracy: 63.930%\n",
            "loss=0.056212205439805984 batch_id=390: 100%|‚ñà| 391/391 [00:33<00:00, 12.44it/s]\n",
            "\n",
            "Epoch: 20 Train set: Average loss: 0.0009, Accuracy: 95.976%\n",
            "Epoch: 20 Test set: Average loss: 0.8576, Accuracy: 75.220%\n",
            "Model saved as Test Accuracy increased from  72.79  to  75.22\n",
            "loss=0.032071392983198166 batch_id=390: 100%|‚ñà| 391/391 [00:33<00:00, 12.44it/s]\n",
            "\n",
            "Epoch: 21 Train set: Average loss: 0.0004, Accuracy: 98.834%\n",
            "Epoch: 21 Test set: Average loss: 0.8842, Accuracy: 73.890%\n",
            "loss=0.1917191445827484 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.33it/s]\n",
            "\n",
            "Epoch: 22 Train set: Average loss: 0.0008, Accuracy: 96.758%\n",
            "Epoch: 22 Test set: Average loss: 1.2906, Accuracy: 64.560%\n",
            "loss=0.3346017301082611 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.55it/s]\n",
            "\n",
            "Epoch: 23 Train set: Average loss: 0.0019, Accuracy: 91.634%\n",
            "Epoch: 23 Test set: Average loss: 1.7697, Accuracy: 53.080%\n",
            "loss=0.20274439454078674 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:33<00:00, 12.41it/s]\n",
            "\n",
            "Epoch: 24 Train set: Average loss: 0.0023, Accuracy: 89.702%\n",
            "Epoch: 24 Test set: Average loss: 0.9839, Accuracy: 68.090%\n",
            "loss=0.22124524414539337 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:33<00:00, 12.46it/s]\n",
            "\n",
            "Epoch: 25 Train set: Average loss: 0.0025, Accuracy: 89.000%\n",
            "Epoch: 25 Test set: Average loss: 1.4039, Accuracy: 60.340%\n",
            "loss=0.3009226322174072 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.46it/s]\n",
            "\n",
            "Epoch: 26 Train set: Average loss: 0.0026, Accuracy: 88.444%\n",
            "Epoch: 26 Test set: Average loss: 1.2885, Accuracy: 63.980%\n",
            "loss=0.3329128324985504 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.40it/s]\n",
            "\n",
            "Epoch: 27 Train set: Average loss: 0.0023, Accuracy: 89.760%\n",
            "Epoch: 27 Test set: Average loss: 1.0957, Accuracy: 65.090%\n",
            "loss=0.1789998710155487 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.39it/s]\n",
            "\n",
            "Epoch: 28 Train set: Average loss: 0.0019, Accuracy: 91.564%\n",
            "Epoch: 28 Test set: Average loss: 0.7308, Accuracy: 75.620%\n",
            "Model saved as Test Accuracy increased from  75.22  to  75.62\n",
            "loss=0.16852621734142303 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:33<00:00, 12.45it/s]\n",
            "\n",
            "Epoch: 29 Train set: Average loss: 0.0014, Accuracy: 93.538%\n",
            "Epoch: 29 Test set: Average loss: 1.2581, Accuracy: 67.180%\n",
            "loss=0.05744447186589241 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:33<00:00, 12.43it/s]\n",
            "\n",
            "Epoch: 30 Train set: Average loss: 0.0008, Accuracy: 96.766%\n",
            "Epoch: 30 Test set: Average loss: 0.8979, Accuracy: 72.490%\n",
            "loss=0.07563678920269012 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:33<00:00, 12.43it/s]\n",
            "\n",
            "Epoch: 31 Train set: Average loss: 0.0003, Accuracy: 99.198%\n",
            "Epoch: 31 Test set: Average loss: 1.0112, Accuracy: 71.260%\n",
            "loss=0.08916802704334259 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:33<00:00, 12.43it/s]\n",
            "\n",
            "Epoch: 32 Train set: Average loss: 0.0003, Accuracy: 98.994%\n",
            "Epoch: 32 Test set: Average loss: 1.0525, Accuracy: 71.180%\n",
            "loss=0.2298876941204071 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.37it/s]\n",
            "\n",
            "Epoch: 33 Train set: Average loss: 0.0014, Accuracy: 93.476%\n",
            "Epoch: 33 Test set: Average loss: 1.1797, Accuracy: 61.510%\n",
            "loss=0.22017773985862732 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:33<00:00, 12.16it/s]\n",
            "\n",
            "Epoch: 34 Train set: Average loss: 0.0021, Accuracy: 90.714%\n",
            "Epoch: 34 Test set: Average loss: 0.9703, Accuracy: 69.160%\n",
            "loss=0.5297974348068237 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.48it/s]\n",
            "\n",
            "Epoch: 35 Train set: Average loss: 0.0023, Accuracy: 89.644%\n",
            "Epoch: 35 Test set: Average loss: 0.9655, Accuracy: 67.800%\n",
            "loss=0.4955720901489258 batch_id=390: 100%|‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 12.48it/s]\n",
            "\n",
            "Epoch: 36 Train set: Average loss: 0.0024, Accuracy: 89.400%\n",
            "Epoch: 36 Test set: Average loss: 1.7471, Accuracy: 54.180%\n",
            "loss=0.20329225063323975 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:33<00:00, 12.50it/s]\n",
            "\n",
            "Epoch: 37 Train set: Average loss: 0.0023, Accuracy: 89.866%\n",
            "Epoch: 37 Test set: Average loss: 0.8114, Accuracy: 74.820%\n",
            "loss=0.15387949347496033 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:33<00:00, 12.46it/s]\n",
            "\n",
            "Epoch: 38 Train set: Average loss: 0.0019, Accuracy: 91.722%\n",
            "Epoch: 38 Test set: Average loss: 1.0105, Accuracy: 67.900%\n",
            "loss=0.22661474347114563 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:33<00:00, 12.38it/s]\n",
            "\n",
            "Epoch: 39 Train set: Average loss: 0.0014, Accuracy: 93.632%\n",
            "Epoch: 39 Test set: Average loss: 1.3983, Accuracy: 64.320%\n",
            "loss=0.07342216372489929 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:33<00:00, 12.53it/s]\n",
            "\n",
            "Epoch: 40 Train set: Average loss: 0.0009, Accuracy: 96.284%\n",
            "Epoch: 40 Test set: Average loss: 0.9350, Accuracy: 71.970%\n",
            "loss=0.02885616384446621 batch_id=390: 100%|‚ñà‚ñà| 391/391 [00:33<00:00, 12.42it/s]\n",
            "\n",
            "Epoch: 41 Train set: Average loss: 0.0003, Accuracy: 99.098%\n",
            "Epoch: 41 Test set: Average loss: 1.0285, Accuracy: 69.890%\n",
            "loss=0.01794871687889099 batch_id=222:  57%|‚ñà‚ñè| 223/391 [00:18<00:14, 11.73it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl-c pressed.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 255. Press ctrl-c to abort syncing.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/My Drive/EVA4/RekogNizer/train_s9_new.py\", line 114, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/My Drive/EVA4/RekogNizer/train_s9_new.py\", line 91, in main\n",
            "    criterion=criterion,save_best=True,lars_mode=False,batch_step=True)\n",
            "  File \"/content/drive/My Drive/EVA4/RekogNizer/traintest.py\", line 239, in execute_model\n",
            "    batch_step=batch_step)\n",
            "  File \"/content/drive/My Drive/EVA4/RekogNizer/traintest.py\", line 123, in train\n",
            "    output = model(data)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/drive/My Drive/EVA4/RekogNizer/QuizDNN.py\", line 64, in forward\n",
            "    x12 = self.gap_linear(x11)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\", line 100, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\", line 345, in forward\n",
            "    return self.conv2d_forward(input, self.weight)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\", line 342, in conv2d_forward\n",
            "    self.padding, self.dilation, self.groups)\n",
            "KeyboardInterrupt\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 4113\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                        Test Loss 1.028467349243164\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                         _runtime 1467.4916625022888\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    Test Accuracy 69.89\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    Learning Rate 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       Train Loss 0.00029810686629265547\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   Train Accuracy 99.098\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       _timestamp 1584471359.4846895\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            _step 41\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing files in wandb/run-20200317_183134-fphnu6h1:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   code/drive/My Drive/EVA4/RekogNizer/train_s9_new.py\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: plus 7 W&B file(s) and 1 media file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced polished-shadow-870: https://app.wandb.ai/rajy4683/news5/runs/fphnu6h1\n",
            "Exception ignored in: <bound method tqdm.__del__ of loss=0.01794871687889099 batch_id=222:  57%|‚ñà‚ñè| 223/391 [00:23<00:14, 11.73it/s]>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 931, in __del__\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 1133, in close\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 496, in _decr_instances\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_monitor.py\", line 51, in exit\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 521, in set\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 364, in notify_all\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 347, in notify\n",
            "TypeError: 'NoneType' object is not callable\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}